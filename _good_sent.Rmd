---
author: "楊舒晴"
title: "台灣升大學考試國寫情意題佳作詞頻相關研究"
date: |
  | 2021-05-30
output:
  html_document:
    number_sections: yes
    highlight: tango
    toc: yes
    toc_float:
      collapsed: no
    css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,comment = '#>',error=TRUE, results = 'hold', out.width='70%', fig.align = 'center', message = FALSE)
```

# 讀檔
```{r}
id <- list.files("./data_set/") # 文章的檔名
contents <- vector("character", length(id)) # 創一個長度與文章數相同的vector

# 將文章內容讀進來，並放入contents這個變數中(不分段)
for (i in seq_along(id)){
  path <- paste0("./data_set/", id[i])
  contents[i] <- paste0(readLines(path, encoding = "UTF-8", warn=FALSE), collapse = "")
}

# 把檔名(id)和文章內容(contents)放進docs_df這個dataFrame中
docs_df <- tibble::tibble(
  id = id,
  content = contents
)
docs_df
```

# 找偉人名人
## 看每篇文章出現幾個偉人、名人
```{r}
library(stringr)
library(dplyr)

# 將放有偉人、名人名字的txt檔讀進來，存進names這個變數中
names <- readLines("./names.txt", encoding = "UTF-8", warn=FALSE)
names <- paste0(names, "、", collapse = "")
names <- unique(strsplit(names, split = "、")[[1]]) 

# 統計各篇文章出現幾個偉人、名人(若重複提到只計算一次)，儲存結果於docs_df的name_times欄位中
docs_df$name_times <- unlist(lapply(contents, function(x){sum(str_detect(x, names))}))

# 看結果
docs_df
```

## 製圖
```{r}
#選用主題
library(dplyr)
library(ggplot2)
library(readr)
library (tidyverse)
library(tidytext)
library(ggrepel)
library(ggthemr)

ggthemr('dust')
#製圖

docs_df1 <-docs_df%>% group_by(name_times)%>%summarise(count =n(),percent =n()/208)
ggplot(docs_df1, aes(x=reorder(name_times,-count),y=count)) +
       geom_bar(width = 0.8, stat = "identity") +
   
#加上標題
labs(title="大考佳作出現名人次數分佈狀況",x="出現次數",y="篇數")+

#修改標籤名字
theme(text=element_text(size=12))+
geom_text(aes(label = count,y = -10),colour="black",size=4)+
geom_text(aes(label = paste0(sprintf("%1.1f", percent*100),"%"), y=(count+10)),size=6,position =position_dodge(0.2),colour="brown")
```

## 各年份佳作平均出現幾個名人
```{r}
year <- unlist(lapply(id, function(x){as.integer(strsplit(x, split = "_")[[1]][[2]])}))
docs_df$year <- year
year_df <- docs_df %>%
  group_by(year) %>%
  summarise(average = mean(name_times)) %>%
  arrange(year)
year_df
```



## 哪個名人、偉人出現在最多篇文章中
```{r}
# 名字計數器(傳入某名字，函數會回傳提到此名字的文章有幾篇)
count_times <- function(name){
  count <- 0 
  for(i in seq_along(contents)){
    if (str_detect(contents[[i]], name) == TRUE){
      count <- count + 1
    }
  }
  return (count)
}

# 計算每個名字各出現在幾篇文章中
article_found_Q <- unlist(lapply(names, count_times))

# 出現某名人的文章是哪幾篇
find_article <- function(name){
  article_vec <- c()
  for (i in seq_along(contents)){
    if (str_detect(contents[[i]], name) == TRUE){
        article_vec <- c(article_vec, id[[i]])
    }
  }
  return(paste0(article_vec, " ", collapse = ""))
}
article_found <- unlist(lapply(names, find_article))

# 將名字與篇數放入names_df中
names_df <- tibble::tibble(
  name = names,
  article_found_Q = article_found_Q,
  article_found = article_found
  )

# 看結果
library(dplyr)
names_df %>%
  arrange(desc(article_found_Q)) %>%
  print(n = Inf)
```

## 圖
```{r}
#選用主題
library(dplyr)
library(ggplot2)
library(readr)
library (tidyverse)
library(tidytext)
library(ggrepel)
library(ggthemr)

ggthemr('dust')

#製圖
names_df1 <- names_df %>%
  filter(article_found_Q >= 4)

ggplot(names_df1, aes(x = reorder(name, -article_found_Q), y = article_found_Q)) +
  geom_bar(width = 0.8, stat = "identity") +
  #加上標題
  labs(title = "名人出現次數排行", x = "人名", y = "篇數") +
  #修改標籤名字
  theme(text = element_text(size = 12), axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  geom_text(aes(label = article_found_Q, y=( article_found_Q+1)),size=6,position =position_dodge(0.2),colour="brown")  
```

# 找佳句
```{r}
good_sent <- c()
good_sent_id <- c()

# 含冒號
for (i in seq_along(id)){
  sentences <- unique(str_match_all(contents[[i]], "：(\\w|，){5,}(。|？|！)")[[1]][,1])
  good_sent <- c(good_sent, sentences)
  good_sent_id <- c(good_sent_id, rep(id[i], length(sentences)))
}

# 含引號
for (i in seq_along(id)){
  sentences <- unique(str_match_all(contents[[i]], "「(\\w|，|。|！|；|、){5,}?」")[[1]][,1])
  good_sent <- c(good_sent, sentences)
  good_sent_id <- c(good_sent_id, rep(id[i], length(sentences)))
}

# 拿掉冒號和上下引號
good_sent <- unlist(lapply(good_sent, function(x){str_replace_all(x, "[：「」]", "")}))


# 人工移除不合適結果
good_sent <- good_sent[-c(5, 6, 7, 8, 9, 10, 11, 13, 18, 19, 20, 22, 24, 25, 26, 27, 28, 32, 35, 40, 43, 44, 58, 61, 73, 74, 75, 76, 83, 85, 91, 95, 96, 97, 102, 103, 104, 105, 109, 115, 118, 119, 122, 124, 126, 128, 132, 135, 137, 138, 143, 146, 148, 150, 159, 160, 163, 169, 171, 174, 175, 176, 189, 193, 194, 197, 203, 208, 213, 216, 219, 221, 223, 232, 235, 242, 243, 245, 258, 259, 268, 273, 274, 275, 276, 278, 288, 304, 306, 309, 312, 314, 315, 316, 323, 324, 329, 330, 336, 345, 346, 347)]

good_sent_id <- good_sent_id[-c(5, 6, 7, 8, 9, 10, 11, 13, 18, 19, 20, 22, 24, 25, 26, 27, 28, 32, 35, 40, 43, 44, 58, 61, 73, 74, 75, 76, 83, 85, 91, 95, 96, 97, 102, 103, 104, 105, 109, 115, 118, 119, 122, 124, 126, 128, 132, 135, 137, 138, 143, 146, 148, 150, 159, 160, 163, 169, 171, 174, 175, 176, 189, 193, 194, 197, 203, 208, 213, 216, 219, 221, 223, 232, 235, 242, 243, 245, 258, 259, 268, 273, 274, 275, 276, 278, 288, 304, 306, 309, 312, 314, 315, 316, 323, 324, 329, 330, 336, 345, 346, 347)]

# 佳句
good_sent

# 有引用佳句的文章比例為多少
df_good_sent <- tibble::tibble(id = id)
df_quote <- df_good_sent %>%
  mutate(quote = (id %in% good_sent_id)) %>%
  group_by(quote) %>%
  summarise(quote_Q = n(), percentage = n()/208)
df_quote

```

## 找相似佳句
```{r}
library(jiebaR)

# 去除所有標點符號
good_sent_clean <- unlist(lapply(good_sent, function(x){str_replace_all(x, "[，。！、]", "")}))

# 計算相似度
simhasher = worker("simhash", topn = 10)
for(i in 1:(length(good_sent)-1)){
  for(j in((i+1):length(good_sent))){
    sim <- distance(good_sent_clean[i], good_sent_clean[j], simhasher)$distance
    if (sim < 12){
      if (!(good_sent_id[i] == good_sent_id[j])){
        print(sim)
        print(good_sent_id[i])
        print(good_sent[i])
        print(good_sent_id[j])
        print(good_sent[j])
        print("")
      }
    }
  } 
}
```

