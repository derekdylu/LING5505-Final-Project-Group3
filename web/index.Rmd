---
title: "**台灣升大學考試國寫情意題佳作詞頻相關研究**"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    theme: sandstone
---
第三組 想不到組名

組員：朱修平、盧德原、楊舒晴、陳宛瑩

<br>

<!-- PART1 -->
# **前言**
國寫在升大學考試之國文科目中，與選擇題各佔一半分數之比重，惟我國之國文教學，向來重視古文閱讀、國學常識等，在教學大綱中以選擇題的答寫作為主要教學方向，許多學生對於國寫部分之掌握能力相對不足。因此，本組希望透過分析國寫情意題佳作詞頻，進一步洞察國寫在我國命題方向與佳作取材等寫作方式。從本組分析成果上來看，可以查知國寫範文有＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿等特色。

---

<!-- PART2 -->
# **研究方法**
## **資料來源與介紹**
本組參酌大考中心每年提供之升大學考試國文作文佳作範本，收錄範圍為民國95年至110年學測與98年至110年指考，共計208篇。另外，由於大考中心係提供範文手寫影本，資料前處理較為耗時，為免壓縮後續資料處理時間，106至110年之學測與指考皆各收錄兩筆資料，並以完整結構之作文為主（新式國寫有部分簡答題）。

## **資料前處理**
本組以手動繕打將資料輸入電腦轉換成txt.檔，統一資料格式（例如：分段換行、無空格、完整標點符號、刪除底線、標準化檔名）後，再匯入Ｒ、python進行後續資料分析。
處理後之資料格式範例顯示如下：


---

<!-- PART3 -->
# **佳作基本特性**
(平均長度、平均語句長度、平均段落長度、平均段落數)

---

<!-- PART4 -->
# **佳作常引用名人事蹟或名言佳句嗎?**
## 名人
<div class = "row">

<div class = "col-md-4">
(分析結果描述)
</div>

<div class = "col-md-8">
```{r, echo = FALSE, out.width='100%'}
## 讀檔
id <- list.files("../data_set/") # 文章的檔名
contents <- vector("character", length(id)) # 創一個長度與文章數相同的vector

# 將文章內容讀進來，並放入contents這個變數中(不分段)
for (i in seq_along(id)){
  path <- paste0("../data_set/", id[i])
  contents[i] <- paste0(readLines(path, encoding = "UTF-8", warn=FALSE), collapse = "")
}

# 把檔名(id)和文章內容(contents)放進docs_df這個dataFrame中
docs_df <- tibble::tibble(
  id = id,
  content = contents
)

## 製圖
library(stringr)
library(dplyr)
library(ggplot2)
library(readr)
library (tidyverse)
library(tidytext)
library(ggrepel)
library(ggthemr)

# 將放有偉人、名人名字的txt檔讀進來，存進names這個變數中
names <- readLines("../names.txt", encoding = "UTF-8", warn=FALSE)
names <- paste0(names, "、", collapse = "")
names <- unique(strsplit(names, split = "、")[[1]]) 

# 統計各篇文章出現幾個偉人、名人(若重複提到只計算一次)，儲存結果於docs_df的name_times欄位中
docs_df$name_times <- unlist(lapply(contents, function(x){sum(str_detect(x, names))}))

#製圖
ggthemr('dust')

docs_df1 <-docs_df%>% group_by(name_times)%>%summarise(count =n(),percent =n()/208)
ggplot(docs_df1, aes(x=reorder(name_times,-count),y=count)) +
       geom_bar(width = 0.8, stat = "identity") +
   
#加上標題
labs(title="大考佳作出現名人次數分佈狀況",x="出現次數",y="篇數")+

#修改標籤名字
theme(text=element_text(size=12))+
geom_text(aes(label = count,y = -10),colour="black",size=4)+
geom_text(aes(label = paste0(sprintf("%1.1f", percent*100),"%"), y=(count+10)),size=6,position =position_dodge(0.2),colour="brown")
```
</div>
</div>

<br>

<div class = "row">

<div class = "col-md-4">
(分析結果描述)
</div>

<div class = "col-md-8">
```{r, echo = FALSE, out.width='100%'}
# 哪個名人、偉人出現在最多篇文章中
# 名字計數器(傳入某名字，函數會回傳提到此名字的文章有幾篇)
count_times <- function(name){
  count <- 0 
  for(i in seq_along(contents)){
    if (str_detect(contents[[i]], name) == TRUE){
      count <- count + 1
    }
  }
  return (count)
}

# 計算每個名字各出現在幾篇文章中
article_found_Q <- unlist(lapply(names, count_times))

# 出現某名人的文章是哪幾篇
find_article <- function(name){
  article_vec <- c()
  for (i in seq_along(contents)){
    if (str_detect(contents[[i]], name) == TRUE){
        article_vec <- c(article_vec, id[[i]])
    }
  }
  return(paste0(article_vec, " ", collapse = ""))
}
article_found <- unlist(lapply(names, find_article))

# 將名字與篇數放入names_df中
names_df <- tibble::tibble(
  name = names,
  article_found_Q = article_found_Q,
  article_found = article_found
  )

## 圖
ggthemr('dust')

#製圖
names_df1 <- names_df %>%
  filter(article_found_Q >= 4)

ggplot(names_df1, aes(x = reorder(name, -article_found_Q), y = article_found_Q)) +
  geom_bar(width = 0.8, stat = "identity") +
  #加上標題
  labs(title = "名人出現次數排行", x = "人名", y = "篇數") +
  #修改標籤名字
  theme(text = element_text(size = 12), axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  geom_text(aes(label = article_found_Q, y=( article_found_Q+1)),size=6,position =position_dodge(0.2),colour="brown")  
```
</div>
</div>

## 名言佳句
```{r, echo=FALSE, attr.output='style="max-height: 300px;"'}
good_sent <- c()
good_sent_id <- c()

# 含冒號
for (i in seq_along(id)){
  sentences <- unique(str_match_all(contents[[i]], "：(\\w|，){5,}(。|？|！)")[[1]][,1])
  good_sent <- c(good_sent, sentences)
  good_sent_id <- c(good_sent_id, rep(id[i], length(sentences)))
}

# 含引號
for (i in seq_along(id)){
  sentences <- unique(str_match_all(contents[[i]], "「(\\w|，|。|！|；|、){5,}?」")[[1]][,1])
  good_sent <- c(good_sent, sentences)
  good_sent_id <- c(good_sent_id, rep(id[i], length(sentences)))
}

# 拿掉冒號和上下引號
good_sent <- unlist(lapply(good_sent, function(x){str_replace_all(x, "[：「」]", "")}))


# 人工移除不合適結果
good_sent <- good_sent[-c(5, 6, 7, 8, 9, 10, 11, 13, 18, 19, 20, 22, 24, 25, 26, 27, 28, 32, 35, 40, 43, 44, 58, 61, 73, 74, 75, 76, 83, 85, 91, 95, 96, 97, 102, 103, 104, 105, 109, 115, 118, 119, 122, 124, 126, 128, 132, 135, 137, 138, 143, 146, 148, 150, 159, 160, 163, 169, 171, 174, 175, 176, 189, 193, 194, 197, 203, 208, 213, 216, 219, 221, 223, 232, 235, 242, 243, 245, 258, 259, 268, 273, 274, 275, 276, 278, 288, 304, 306, 309, 312, 314, 315, 316, 323, 324, 329, 330, 336, 345, 346, 347)]

good_sent_id <- good_sent_id[-c(5, 6, 7, 8, 9, 10, 11, 13, 18, 19, 20, 22, 24, 25, 26, 27, 28, 32, 35, 40, 43, 44, 58, 61, 73, 74, 75, 76, 83, 85, 91, 95, 96, 97, 102, 103, 104, 105, 109, 115, 118, 119, 122, 124, 126, 128, 132, 135, 137, 138, 143, 146, 148, 150, 159, 160, 163, 169, 171, 174, 175, 176, 189, 193, 194, 197, 203, 208, 213, 216, 219, 221, 223, 232, 235, 242, 243, 245, 258, 259, 268, 273, 274, 275, 276, 278, 288, 304, 306, 309, 312, 314, 315, 316, 323, 324, 329, 330, 336, 345, 346, 347)]

# 佳句
good_sent

```

## 相似的名言佳句
```{r, echo=FALSE}
library(jiebaR)

# 去除所有標點符號
good_sent_clean <- unlist(lapply(good_sent, function(x){str_replace_all(x, "[，。！、]", "")}))

# 計算相似度
simhasher = worker("simhash", topn = 10)
for(i in 1:(length(good_sent)-1)){
  for(j in((i+1):length(good_sent))){
    sim <- distance(good_sent_clean[i], good_sent_clean[j], simhasher)$distance
    if (sim < 12){
      if (!(good_sent_id[i] == good_sent_id[j])){
        cat(good_sent_id[i], good_sent[i], "\n")
        cat(good_sent_id[j], good_sent[j], "\n")
        cat("\n")
      }
    }
  } 
}
```

---

<!-- PART5-->
# **冷僻詞分析**
(...)

